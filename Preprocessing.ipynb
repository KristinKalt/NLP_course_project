{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e4c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc98e5",
   "metadata": {},
   "source": [
    "## Load data set into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a6b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration copenlu--nlp_course_tydiqa-cceecfb5416d988a\n",
      "Found cached dataset parquet (/Users/dpr577/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-cceecfb5416d988a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7abd7e5dea4b0f99cf482462ea09d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "29868"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
    "train_set = dataset[\"train\"]\n",
    "validation_set = dataset[\"validation\"]\n",
    "\n",
    "df_val = pd.DataFrame(validation_set)\n",
    "df_val = df_val[df_val.language.isin(['finnish', 'english', 'japanese'])]\n",
    "\n",
    "df_train = pd.DataFrame(train_set)\n",
    "df_train = df_train[df_train.language.isin(['finnish', 'english', 'japanese'])]\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1a38c",
   "metadata": {},
   "source": [
    "## 1.1 Preprocessing and Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e46d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_df(df, language):\n",
    "    return df[df['language'] == language]\n",
    "\n",
    "df_train_FI = get_lang_df(df_train, 'finnish').copy()\n",
    "df_train_JAP = get_lang_df(df_train, 'japanese').copy()\n",
    "df_train_EN = get_lang_df(df_train, 'english').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c066a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return \"\".join([char.lower() for char in text if char not in string.punctuation]) \n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [w for w in tokens if not w in stop_words]\n",
    "\n",
    "def tokenize_EN(df, col: str):\n",
    "    df[col+'tokens'] = df[col].apply(word_tokenize)\n",
    "    df[col+'tokens_cleaned'] = df[col].apply(clean_text)\n",
    "    df[col+'tokens_cleaned'] = df[col+'tokens_cleaned'].apply(word_tokenize)\n",
    "    df[col+'tokens_cleaned'] = df[col+'tokens_cleaned'].apply(remove_stopwords)\n",
    "\n",
    "def tokenize_FI(df):\n",
    "    df['tokens'] = df['question_text'].apply(word_tokenize, language='finnish')\n",
    "\n",
    "def helper_func_JAP(question):\n",
    "    tokenizer_obj = dictionary.Dictionary().create()\n",
    "    res_list = tokenizer_obj.tokenize(question)\n",
    "    return [x.surface() for x in res_list]\n",
    "\n",
    "def tokenize_JAP(df):\n",
    "    df['tokens'] = df['question_text'].apply(helper_func_JAP)\n",
    "\n",
    "\n",
    "tokenize_EN(df_train_EN, 'question_text')\n",
    "#tokenize_FI(df_train_FI)\n",
    "#tokenize_JAP(df_train_JAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "421b05b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“', 'ダン', '”', ' ', 'ダニエル', '・', 'ジャドソン', '・', 'キャラハン', 'の', '出身', 'は', 'どこ']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ\"\n",
    "helper_func_JAP(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1473ab00",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3798'>3799</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3799'>3800</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3800'>3801</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tokens'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mlast_token\u001b[38;5;241m.\u001b[39mvalue_counts()[:n]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#For English\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df_res \u001b[38;5;241m=\u001b[39m \u001b[43mget_most_common_first_n_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_EN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m get_most_common_last_n_tokens(df_train_EN, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m, in \u001b[0;36mget_most_common_first_n_tokens\u001b[0;34m(df, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_most_common_first_n_tokens\u001b[39m(df, n):\n\u001b[0;32m----> 2\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_token\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mfirst_token\u001b[38;5;241m.\u001b[39mvalue_counts()[:n]\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3802'>3803</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3803'>3804</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3804'>3805</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3805'>3806</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3806'>3807</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3799'>3800</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3800'>3801</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3801'>3802</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3802'>3803</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3803'>3804</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3804'>3805</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3805'>3806</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3806'>3807</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tokens'"
     ]
    }
   ],
   "source": [
    "def get_most_common_first_n_tokens(df, n):\n",
    "    df['first_token'] = df['tokens'].apply(lambda x: x[0])\n",
    "    return df.first_token.value_counts()[:n]\n",
    "\n",
    "def get_most_common_last_n_tokens(df, n):\n",
    "    df['last_token'] = df['tokens'].apply(lambda x: x[-1] if x[-1].isalpha() else x[-2])\n",
    "    return df.last_token.value_counts()[:n]\n",
    "\n",
    "#For English\n",
    "df_res = get_most_common_first_n_tokens(df_train_EN, 10)\n",
    "get_most_common_last_n_tokens(df_train_EN, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c55c15fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "syntyi          1072\n",
       "on               723\n",
       "kuoli            720\n",
       "tarkoittaa       488\n",
       "perustettu       476\n",
       "syntynyt         398\n",
       "oli              382\n",
       "perustettiin     351\n",
       "sijaitsee        258\n",
       "pinta-ala        214\n",
       "Name: last_token, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finnish\n",
    "get_most_common_first_n_tokens(df_train_FI, 10)\n",
    "get_most_common_last_n_tokens(df_train_FI, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ef7f15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/z1y7t00n7bd8lm8r0r4sy2b40000gn/T/ipykernel_3860/2224523845.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  res_JAP.to_latex()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llrlr}\\n\\\\toprule\\n{} &        0 &    1 &   2 &     3 \\\\\\\\\\n\\\\midrule\\n0 &       日本 &  354 &   た &  2115 \\\\\\\\\\n1 &        『 &  306 &   か &  1305 \\\\\\\\\\n2 &       世界 &   94 &   何 &  1192 \\\\\\\\\\n3 &      ジョン &   58 &  いつ &   996 \\\\\\\\\\n4 &        第 &   56 &   は &   932 \\\\\\\\\\n5 &  アメリカ合衆国 &   54 &  どこ &   884 \\\\\\\\\\n6 &        「 &   50 &   誰 &   746 \\\\\\\\\\n7 &     アメリカ &   50 &  ある &   174 \\\\\\\\\\n8 &    ウィリアム &   44 &  だれ &    64 \\\\\\\\\\n9 &     ジョージ &   44 &  いる &    42 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Japanese\n",
    "res_JAP_first = get_most_common_first_n_tokens(df_train_JAP, 10).reset_index()\n",
    "res_JAP_last = get_most_common_last_n_tokens(df_train_JAP, 10).reset_index()\n",
    "res_JAP = pd.concat([res_JAP_first, res_JAP_last], ignore_index=True, axis=1)\n",
    "res_JAP.to_latex()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2edbbb3",
   "metadata": {},
   "source": [
    "## 1.2 Binary Question Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124b9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61501f79",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b0173d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "      <th>question_texttokens</th>\n",
       "      <th>question_texttokens_cleaned</th>\n",
       "      <th>doc_tokens</th>\n",
       "      <th>word_count_doc</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>When was quantum field theory developed?</td>\n",
       "      <td>Quantum field theory</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [159], 'answer_text': ['1920s']}</td>\n",
       "      <td>Quantum field theory naturally began with the ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Quantum%20field%...</td>\n",
       "      <td>[When, was, quantum, field, theory, developed, ?]</td>\n",
       "      <td>[quantum, field, theory, developed]</td>\n",
       "      <td>[Quantum, field, theory, naturally, began, wit...</td>\n",
       "      <td>31</td>\n",
       "      <td>1920s</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Who was the first Nobel prize winner for Liter...</td>\n",
       "      <td>List of Nobel laureates in Literature</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [610], 'answer_text': ['Sully...</td>\n",
       "      <td>The Nobel Prize in Literature (Swedish: Nobelp...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List%20of%20Nobe...</td>\n",
       "      <td>[Who, was, the, first, Nobel, prize, winner, f...</td>\n",
       "      <td>[first, nobel, prize, winner, literature]</td>\n",
       "      <td>[The, Nobel, Prize, in, Literature, (, Swedish...</td>\n",
       "      <td>188</td>\n",
       "      <td>Sully Prudhomme</td>\n",
       "      <td>610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>When is the dialectical method used?</td>\n",
       "      <td>Dialectic</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [129], 'answer_text': ['disco...</td>\n",
       "      <td>Dialectic or dialectics (Greek: διαλεκτική, di...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dialectic</td>\n",
       "      <td>[When, is, the, dialectical, method, used, ?]</td>\n",
       "      <td>[dialectical, method, used]</td>\n",
       "      <td>[Dialectic, or, dialectics, (, Greek, :, διαλε...</td>\n",
       "      <td>113</td>\n",
       "      <td>discourse between two or more people holding d...</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Who invented Hangul?</td>\n",
       "      <td>Origin of Hangul</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [88], 'answer_text': ['Sejong...</td>\n",
       "      <td>Hangul was personally created and promulgated ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Origin%20of%20Ha...</td>\n",
       "      <td>[Who, invented, Hangul, ?]</td>\n",
       "      <td>[invented, hangul]</td>\n",
       "      <td>[Hangul, was, personally, created, and, promul...</td>\n",
       "      <td>69</td>\n",
       "      <td>Sejong the Great</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>What do Grasshoppers eat?</td>\n",
       "      <td>Grasshopper</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [0], 'answer_text': ['Grassho...</td>\n",
       "      <td>Grasshoppers are plant-eaters, with a few spec...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Grasshopper</td>\n",
       "      <td>[What, do, Grasshoppers, eat, ?]</td>\n",
       "      <td>[grasshoppers, eat]</td>\n",
       "      <td>[Grasshoppers, are, plant-eaters, ,, with, a, ...</td>\n",
       "      <td>125</td>\n",
       "      <td>Grasshoppers are plant-eaters, with a few spec...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question_text  \\\n",
       "26            When was quantum field theory developed?   \n",
       "43   Who was the first Nobel prize winner for Liter...   \n",
       "112               When is the dialectical method used?   \n",
       "123                               Who invented Hangul?   \n",
       "125                          What do Grasshoppers eat?   \n",
       "\n",
       "                            document_title language  \\\n",
       "26                    Quantum field theory  english   \n",
       "43   List of Nobel laureates in Literature  english   \n",
       "112                              Dialectic  english   \n",
       "123                       Origin of Hangul  english   \n",
       "125                            Grasshopper  english   \n",
       "\n",
       "                                           annotations  \\\n",
       "26   {'answer_start': [159], 'answer_text': ['1920s']}   \n",
       "43   {'answer_start': [610], 'answer_text': ['Sully...   \n",
       "112  {'answer_start': [129], 'answer_text': ['disco...   \n",
       "123  {'answer_start': [88], 'answer_text': ['Sejong...   \n",
       "125  {'answer_start': [0], 'answer_text': ['Grassho...   \n",
       "\n",
       "                                    document_plaintext  \\\n",
       "26   Quantum field theory naturally began with the ...   \n",
       "43   The Nobel Prize in Literature (Swedish: Nobelp...   \n",
       "112  Dialectic or dialectics (Greek: διαλεκτική, di...   \n",
       "123  Hangul was personally created and promulgated ...   \n",
       "125  Grasshoppers are plant-eaters, with a few spec...   \n",
       "\n",
       "                                          document_url  \\\n",
       "26   https://en.wikipedia.org/wiki/Quantum%20field%...   \n",
       "43   https://en.wikipedia.org/wiki/List%20of%20Nobe...   \n",
       "112            https://en.wikipedia.org/wiki/Dialectic   \n",
       "123  https://en.wikipedia.org/wiki/Origin%20of%20Ha...   \n",
       "125          https://en.wikipedia.org/wiki/Grasshopper   \n",
       "\n",
       "                                   question_texttokens  \\\n",
       "26   [When, was, quantum, field, theory, developed, ?]   \n",
       "43   [Who, was, the, first, Nobel, prize, winner, f...   \n",
       "112      [When, is, the, dialectical, method, used, ?]   \n",
       "123                         [Who, invented, Hangul, ?]   \n",
       "125                   [What, do, Grasshoppers, eat, ?]   \n",
       "\n",
       "                   question_texttokens_cleaned  \\\n",
       "26         [quantum, field, theory, developed]   \n",
       "43   [first, nobel, prize, winner, literature]   \n",
       "112                [dialectical, method, used]   \n",
       "123                         [invented, hangul]   \n",
       "125                        [grasshoppers, eat]   \n",
       "\n",
       "                                            doc_tokens  word_count_doc  \\\n",
       "26   [Quantum, field, theory, naturally, began, wit...              31   \n",
       "43   [The, Nobel, Prize, in, Literature, (, Swedish...             188   \n",
       "112  [Dialectic, or, dialectics, (, Greek, :, διαλε...             113   \n",
       "123  [Hangul, was, personally, created, and, promul...              69   \n",
       "125  [Grasshoppers, are, plant-eaters, ,, with, a, ...             125   \n",
       "\n",
       "                                           answer_text  answer_start  \\\n",
       "26                                               1920s           159   \n",
       "43                                     Sully Prudhomme           610   \n",
       "112  discourse between two or more people holding d...           129   \n",
       "123                                   Sejong the Great            88   \n",
       "125  Grasshoppers are plant-eaters, with a few spec...             0   \n",
       "\n",
       "     answerable  \n",
       "26            1  \n",
       "43            1  \n",
       "112           1  \n",
       "123           1  \n",
       "125           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_col_answer(text):\n",
    "    return text['answer_text'][0]\n",
    "\n",
    "def make_col_answer_start(text):\n",
    "    return text['answer_start'][0]\n",
    "\n",
    "df_train_EN['answer_text'] = df_train_EN['annotations'].apply(make_col_answer)\n",
    "df_train_EN['answer_start'] = df_train_EN['annotations'].apply(make_col_answer_start)\n",
    "df_train_EN['answerable'] = df_train_EN['answer_start'].apply(lambda x : 0 if x == -1 else 1)\n",
    "\n",
    "df_train_EN.head()\n",
    "\n",
    "tokenize_EN(df_train_EN, 'document_plaintext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3243f987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train_EN[df_train_EN['answerable'] == 0].iloc[82]['document_plaintexttokens_cleaned'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f88ba6",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9f17cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'document_plaintexttokens_cleaned'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3798'>3799</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3799'>3800</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3800'>3801</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'document_plaintexttokens_cleaned'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 32\u001b[0m\n\u001b[1;32m     26\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverlap_doc_question\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(calculate_overlap)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#count_words_in_doc(df_train_EN)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#get_bow(df_train_EN)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mget_overlap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_EN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m df_train_EN\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn [81], line 26\u001b[0m, in \u001b[0;36mget_overlap\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_overlap\u001b[39m(row):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument_plaintexttokens_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverlap_doc_question\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_overlap\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py:9558\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=9546'>9547</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=9548'>9549</a>\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=9549'>9550</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=9550'>9551</a>\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=9555'>9556</a>\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=9556'>9557</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/frame.py?line=9557'>9558</a>\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py:741\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=737'>738</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=738'>739</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=740'>741</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py:868\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=866'>867</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=867'>868</a>\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=869'>870</a>\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=870'>871</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py:884\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=880'>881</a>\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=881'>882</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=882'>883</a>\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=883'>884</a>\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=884'>885</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=885'>886</a>\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=886'>887</a>\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/apply.py?line=887'>888</a>\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [81], line 24\u001b[0m, in \u001b[0;36mget_overlap.<locals>.calculate_overlap\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_overlap\u001b[39m(row):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocument_plaintexttokens_cleaned\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py:982\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=978'>979</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=980'>981</a>\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=981'>982</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=983'>984</a>\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=984'>985</a>\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=985'>986</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=986'>987</a>\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py:1092\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=1088'>1089</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=1090'>1091</a>\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=1091'>1092</a>\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/series.py?line=1092'>1093</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3799'>3800</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3800'>3801</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3801'>3802</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3802'>3803</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3803'>3804</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3804'>3805</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3805'>3806</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/dpr577/Workspace/NLP_course/NLP_course_project/nlp-venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3806'>3807</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'document_plaintexttokens_cleaned'"
     ]
    }
   ],
   "source": [
    "def count_words_in_doc(df):\n",
    "    df['doc_tokens'] = df['document_plaintext'].apply(word_tokenize)\n",
    "    df[\"word_count_doc\"] = df['doc_tokens'].str.len()\n",
    "\n",
    "def get_bow(df):\n",
    "    def get_question_vocab():\n",
    "        token_list_temp = df_train_EN.question_texttokens_cleaned.to_list()\n",
    "        return  [item for sublist in token_list_temp for item in sublist]\n",
    "\n",
    "    vocab = get_question_vocab()\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(vocab)\n",
    "\n",
    "    def transform_bow(cell):\n",
    "        res = vectorizer.transform(cell)\n",
    "        return res.toarray()\n",
    "    \n",
    "    df['bow_question'] = df['question_texttokens_cleaned'].apply(transform_bow)\n",
    "\n",
    "def get_overlap(df):\n",
    "    #df['overlap_doc_question'] = set(df['question_texttokens_cleaned'])&set(df['document_plaintexttokens_cleaned'])\n",
    "\n",
    "    def calculate_overlap(row):\n",
    "        return row['document_plaintexttokens_cleaned']\n",
    "\n",
    "    df['overlap_doc_question'] = df.apply(calculate_overlap)\n",
    "\n",
    "\n",
    "\n",
    "#count_words_in_doc(df_train_EN)\n",
    "#get_bow(df_train_EN)\n",
    "get_overlap(df_train_EN)\n",
    "df_train_EN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56221cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['louisemariemadeleine',\n",
       " 'guillaume',\n",
       " 'de',\n",
       " 'fontaine',\n",
       " 'marriage',\n",
       " 'known',\n",
       " 'madame',\n",
       " 'dupin',\n",
       " '28',\n",
       " 'october',\n",
       " '1706',\n",
       " '–',\n",
       " '20',\n",
       " 'november',\n",
       " '1799',\n",
       " 'french',\n",
       " 'saloniste']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1 = ['does', 'am', 'am', 'good', 'I']\n",
    "doc_2 = ['does', 'does', 'am' ]\n",
    "doc_3 = df_train_EN.iloc[82]['document_plaintexttokens_cleaned']\n",
    "doc_4 = df_train_EN.iloc[82]['question_texttokens_cleaned']\n",
    "\n",
    "set(doc_3)&set(doc_4)\n",
    "doc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb3d258a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "  \n",
    "    \n",
    "vec = CountVectorizer()\n",
    "vec.fit(vocab)\n",
    "vector_1 = vec.transform(doc_1)\n",
    "vector_1.toarray()\n",
    "\n",
    "\n",
    "#vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f299fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_EN.iloc[0]['bow_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db5135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-venv",
   "language": "python",
   "name": "nlp-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
